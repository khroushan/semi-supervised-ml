{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbf8977a-4879-4467-9cc0-2a99534bef26",
   "metadata": {},
   "source": [
    "## Semi-Supervised Learning Experiments\n",
    "\n",
    "    Amin Ahmadi\n",
    "    date created: Jun 9 2022\n",
    "    last update: Jun 16 2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a2f88-e046-4eef-a32e-c8dcaa4bf2dd",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "    [ ] Read and Save data (labeled and unlabled) into a proper format \n",
    "    [ ] Reduce labeled data until there is a sudden change in the performance, then use unlabeled dataset.\n",
    "    [ ] The base model should have a prob, maybe start with logistic: `loss = 'log'`\n",
    "    [ ] If it works increase the volume of unlabled data to the saturation point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed0c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25cf802f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb9a2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '../data/aclImdb'\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a729ef19",
   "metadata": {},
   "source": [
    "### Read the reviews into a numpy array\n",
    "\n",
    "Numpy array speed-up operation because the array has a fixed length. It is not possible to store free-length text as an element in a numpy array.\n",
    "\n",
    "The text must be converted to fixed length array then be stored.\n",
    "\n",
    "Let represent each document by `bag of words`:\n",
    "- Go through all documents, get unique words as a `set`\n",
    "- Add new words to the original set\n",
    "- Covert final set of unique words to a dictionary\n",
    "- Count the occurance of each word in document and store in `X`\n",
    "\n",
    "Think about how to shuffle `pos` and `neg` review together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50eb47f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56173"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Home-brewed approach to extract `set` of words\n",
    "\n",
    "# make a dictionary for translation of punctuation\n",
    "# all are replaced by white space\n",
    "replace_punctuation = str.maketrans(string.punctuation, \n",
    "                                    ' ' * len(string.punctuation))\n",
    "\n",
    "train_pos_dir = os.path.join(train_dir, 'pos/')\n",
    "train_neg_dir = os.path.join(train_dir, 'neg/')\n",
    "\n",
    "set_of_words=set()\n",
    "for i, file_name in enumerate(os.listdir(train_pos_dir)):    \n",
    "    file = os.path.join(train_pos_dir, file_name)\n",
    "    with open(file) as f:\n",
    "        set_of_words = set_of_words.union(set(f.read()\\\n",
    "                                               .lower()\\\n",
    "                                               .translate(replace_punctuation)\\\n",
    "                                               .split())\n",
    "                                         )\n",
    "len(set_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f02a92",
   "metadata": {},
   "source": [
    "### Extract files text as a `list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "629bc9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(list_of_files):\n",
    "    \"\"\" Extract text for each file in the list of path to files. The text is \n",
    "    converted to lowercase and punctuation will be removed.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    for i, file in enumerate(list_of_files):\n",
    "        with open(file) as f:\n",
    "            texts.append(f.read().lower()\\\n",
    "                         .translate(replace_punctuation)\n",
    "                        )\n",
    "    return texts\n",
    "\n",
    "def extract_text_keep_original(list_of_files):\n",
    "    \"\"\" Extract text for each file in the list of path to files. The text is \n",
    "    converted to lowercase and punctuation will be removed.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    \n",
    "    for i, file in enumerate(list_of_files):\n",
    "        with open(file) as f:\n",
    "            texts.append(f.read())\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8767e222",
   "metadata": {},
   "source": [
    "### Extract text and store in a `pd.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16454e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train pos Number of texts: 12500\n",
      "train neg Number of texts: 12500\n",
      "train unsup Number of texts: 50000\n",
      "test pos Number of texts: 12500\n",
      "test neg Number of texts: 12500\n"
     ]
    }
   ],
   "source": [
    "dfs = {}\n",
    "for d in ['train', 'test']:\n",
    "    for sub_d in ['pos', 'neg', 'unsup']:\n",
    "        dir_to_read = os.path.join(dataset_dir, d, sub_d)\n",
    "        if os.path.exists(dir_to_read):\n",
    "            file_list =  [os.path.join(dir_to_read, file) \\\n",
    "                           for file in os.listdir(dir_to_read)]\n",
    "            texts = extract_text_keep_original(file_list)\n",
    "            print(d, sub_d, f\"Number of texts: {len(texts)}\")\n",
    "            df_aux = pd.DataFrame({'text':texts, 'review':sub_d})\n",
    "            try:\n",
    "                dfs[d] = pd.concat([dfs[d], df_aux])\n",
    "            except:\n",
    "                dfs[d] = df_aux.copy()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eed693f1-84f9-4a18-a10f-508693b08129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = dfs['train']\n",
    "df_test = dfs['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c09a4bc-b09c-4fc0-b1b8-3535522fb48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unsup    50000\n",
       "pos      12500\n",
       "neg      12500\n",
       "Name: review, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57f7d444-7b02-4911-a3a3-3513adcb9dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos    12500\n",
       "neg    12500\n",
       "Name: review, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77fb244-a26d-46e8-ace1-f25e9db94cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_parquet('../data/imdb_train.parq', engine='pyarrow', compression='gzip')\n",
    "df_test.to_parquet('../data/imdb_test.parq', engine='pyarrow', compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
